# RAG-Mini : SystÃ¨me de Questions-RÃ©ponses sur la Seconde Guerre mondiale

Un systÃ¨me RAG (Retrieval-Augmented Generation) simple et efficace qui permet de poser des questions sur la Seconde Guerre mondiale en utilisant diffÃ©rents types de documents comme source d'information.

## ğŸš€ FonctionnalitÃ©s

- Support de multiples formats de documents (.txt, .pdf, .docx, .csv, .html, .json, .md, .ppt)
- Utilisation d'Ollama pour le traitement local
- Indexation efficace avec FAISS
- Interface simple en ligne de commande
- RÃ©ponses basÃ©es uniquement sur les documents fournis

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- Ollama installÃ© sur votre machine
- ModÃ¨le Mistral tÃ©lÃ©chargÃ© via Ollama

## ğŸ›  Installation

1. Clonez le repository :
```bash
git clone https://github.com/votre-username/rag-mini.git
cd rag-mini
```

2. Installez les dÃ©pendances :
```bash
pip install -r requirements.txt
```

3. TÃ©lÃ©chargez le modÃ¨le Mistral via Ollama :
```bash
ollama pull mistral
```

## ğŸ“ Structure du Projet

```
rag-mini/
â”œâ”€â”€ data/                  # Dossier contenant les documents sources
â”œâ”€â”€ loaders.py            # Gestionnaire de chargement des documents
â”œâ”€â”€ index_documents.py    # Script d'indexation des documents
â”œâ”€â”€ main.py              # Script principal pour les questions-rÃ©ponses
â””â”€â”€ requirements.txt     # DÃ©pendances du projet
```

## ğŸš€ Utilisation

1. Placez vos documents dans le dossier `data/`. Les formats supportÃ©s sont :
   - .txt (fichiers texte)
   - .pdf (documents PDF)
   - .doc/.docx (documents Word)
   - .csv (fichiers CSV)
   - .html/.htm (pages web)
   - .json (fichiers JSON)
   - .md (fichiers Markdown)
   - .ppt/.pptx (prÃ©sentations PowerPoint)

2. Indexez les documents (Ã  faire une seule fois) :
```bash
python index_documents.py
```

3. Lancez le systÃ¨me de questions-rÃ©ponses :
```bash
python main.py
```

4. Posez vos questions sur la Seconde Guerre mondiale !

## ğŸ”§ Configuration

Le systÃ¨me utilise par dÃ©faut :
- Le modÃ¨le Mistral pour les embeddings et les rÃ©ponses
- Une taille de chunk de 1000 caractÃ¨res
- Un chevauchement de 200 caractÃ¨res entre les chunks

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Ouvrir une issue pour signaler un bug
- Proposer une amÃ©lioration via une pull request
- Ajouter de nouveaux types de documents supportÃ©s

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [LangChain](https://github.com/langchain-ai/langchain) pour le framework
- [Ollama](https://ollama.ai/) pour les modÃ¨les locaux
- [FAISS](https://github.com/facebookresearch/faiss) pour l'indexation vectorielle 